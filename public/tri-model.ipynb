{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e4cfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login\n",
      "Login\n",
      "Login\n",
      "From ₹1,649\n",
      "From ₹8000\n",
      "From ₹10190\n",
      "From ₹5,799\n",
      "Up to 70% Off\n",
      "Up to 40% Off\n",
      "From ₹139\n",
      "Upto 75% Off\n",
      "Up to 70% off\n",
      "Up to 70% Off\n",
      "Upto 80% Off\n",
      "Min. 70% Off\n",
      "Min. 50% Off\n",
      "Min. 50% Off\n",
      "Min. 70% Off\n",
      "ASUS ROG Strix SCAR 16 (2023) Core i9 13th Gen\n",
      "ASUS Zenbook 14 OLED (2022)\n",
      "2 in 1 Laptops\n",
      "No Cost EMI\n",
      " Bengaluru, 560103, \n",
      " Bengaluru, 560103, \n",
      " CIN : U51109KA2012PTC066107 \n",
      "044-45614700\n",
      "tals NEE Just 215 999\n",
      "3      Just 15 999\n",
      "Launch Tomorrow 12PM\n",
      "Launch Tomorrow 12PM\n",
      "I  y India s First 32MP Selfie CamTop 50 Deals on ACs  From  26 499 Cartier  Samsung  MarQ  Guaranteed Exchange Offer   Min 24 000\n",
      "  EEETop 50 Deals on ACs From 726 499 Carrer  Samsung  Mar  Guaranteed Exchange Offer   Min 24 000en\n",
      "S   Get Upto  25 000 Off\n",
      "2 Get Upto  25 000 Off\n",
      "4 Fly to Bliss \n",
      "f Akasa Air Flights From 1 299\n",
      "  ok Flights From 21 299EPSON  tei\n",
      "tals NEE Just 215 999\n",
      "3      Just 15 999\n",
      "Launch Tomorrow 12PM\n",
      "Launch Tomorrow 12PM\n",
      "     3   Ye\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer ,XLNetForSequenceClassification\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Paths to the fine-tuned models\n",
    "bert_model_path = r\"I:\\CoDarks\\public\\models\\DPBH_BERT_Fine_Tuned_Model\"\n",
    "xlnet_model_path = r\"I:\\CoDarks\\public\\models\\DPBH_XLNet_Fine_Tuned_Model\"\n",
    "\n",
    "# Load models and tokenizers\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_path)\n",
    "bert_model = BertForSequenceClassification.from_pretrained(bert_model_path)\n",
    "\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model_path)\n",
    "xlnet_model = XLNetForSequenceClassification.from_pretrained(xlnet_model_path)\n",
    "\n",
    "max_seq_length = 512\n",
    "\n",
    "def preprocess_text(tokenizer, text):   \n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, truncation=True)))\n",
    "    return tokens\n",
    "\n",
    "def predict_dark_patterns(models, tokenizers, input_text):\n",
    "    votes = []\n",
    "\n",
    "    for model, tokenizer in zip(models, tokenizers):\n",
    "        input_ids = tokenizer.encode(preprocess_text(tokenizer, input_text), return_tensors='pt', max_length=max_seq_length, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "\n",
    "        probs = softmax(outputs.logits, dim=1).squeeze()\n",
    "        predicted_category = torch.argmax(probs).item()\n",
    "\n",
    "        votes.append(predicted_category)\n",
    "\n",
    "    return votes\n",
    "\n",
    "def count_dark_patterns(text_file):\n",
    "    with open(text_file, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "\n",
    "    # Map category names to numeric labels\n",
    "    category_mapping = {\"Urgency\": 0, \"Not Dark Pattern\": 1, \"Scarcity\": 2, \"Misdirection\": 3, \"Social Proof\": 4,\n",
    "                        \"Obstruction\": 5, \"Sneaking\": 6, \"Forced Action\": 7}\n",
    "\n",
    "    dark_patterns = {category: 0 for category in category_mapping}\n",
    "\n",
    "    sentences = re.split(r'[\\n]', text_content)\n",
    "    \n",
    "    ans= {\n",
    "        \"Urgency\":[],\n",
    "        \"Scarcity\":[],\n",
    "        \"Misdirection\":[],\n",
    "        \"Obstruction\":[],\n",
    "        \"Sneaking\":[],\n",
    "        \"Forced Action\":[],\n",
    "        \"Social Proof\":[]\n",
    "    }\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if not sentence.strip():\n",
    "            continue\n",
    "\n",
    "        individual_predictions = predict_dark_patterns([bert_model, xlnet_model],\n",
    "                                                      [bert_tokenizer, xlnet_tokenizer],\n",
    "                                                      sentence)\n",
    "        \n",
    "#         individual_predictions = predict_dark_patterns([bert_model],\n",
    "#                                                       [bert_tokenizer],\n",
    "#                                                       sentence)\n",
    "\n",
    "        # Get majority voted prediction\n",
    "        majority_category = max(set(individual_predictions), key=individual_predictions.count)\n",
    "        category_name = next(key for key, value in category_mapping.items() if value == majority_category)\n",
    "\n",
    "        if (category_name != \"Not Dark Pattern\"):\n",
    "            ans[category_name].append(sentence)\n",
    "            print(sentence)\n",
    "        \n",
    "    return ans\n",
    "\n",
    "result = count_dark_patterns('I:\\CoDarks\\server\\output.txt')\n",
    "\n",
    "json_data = json.dumps(result)\n",
    "with open('I:\\CoDarks\\server\\data.json', 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cecb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
